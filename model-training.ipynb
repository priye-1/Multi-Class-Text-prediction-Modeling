{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb25f564",
   "metadata": {},
   "source": [
    "### The project inplements Supervised Machine learning to predict rating based on review text.\n",
    "<br>\n",
    "- Supervised ML is used due to the presence of target variables in dataset.<br>\n",
    "- A Multi-class classification technique is implemented, therefore the classifiers -  SVM and Naive Bayes will be used to train and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e13ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d84d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/6c/31c623a656ab66e938b2432cb8e41dc5497dec670ff07e1e74989ee0ab77/scikit_learn-0.24.2-cp38-cp38-macosx_10_13_x86_64.whl (7.2MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /Users/tamunopriye/Documents/Invisible/.venv/lib/python3.8/site-packages (from scikit-learn) (1.7.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/tamunopriye/Documents/Invisible/.venv/lib/python3.8/site-packages (from scikit-learn) (1.21.0)\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 threadpoolctl-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "!pip install scikit-learn\n",
    "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git\n",
    "!pip install spacy==2.2.3\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install beautifulsoup4==4.9.1\n",
    "!pip install textblob==0.15.3\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24be1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>category</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>shop</th>\n",
       "      <th>review_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501</td>\n",
       "      <td>By Terry</td>\n",
       "      <td>155.00</td>\n",
       "      <td>Makeup - Foundation - Mousse and Cream Foundation</td>\n",
       "      <td>I love this - just makes you look so healthy a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>spacenk.com</td>\n",
       "      <td>2021-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501</td>\n",
       "      <td>By Terry</td>\n",
       "      <td>155.00</td>\n",
       "      <td>Makeup - Foundation - Mousse and Cream Foundation</td>\n",
       "      <td>Great coverage while allowing your skin to shi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Beautiful coverage</td>\n",
       "      <td>mecca.com.au</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501</td>\n",
       "      <td>By Terry</td>\n",
       "      <td>155.00</td>\n",
       "      <td>Makeup - Foundation - Mousse and Cream Foundation</td>\n",
       "      <td>Absolutely wonderful product. I use this as a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Lovely glowy base product!</td>\n",
       "      <td>spacenk.com</td>\n",
       "      <td>2021-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501</td>\n",
       "      <td>By Terry</td>\n",
       "      <td>155.00</td>\n",
       "      <td>Makeup - Foundation - Mousse and Cream Foundation</td>\n",
       "      <td>Amazing price and quick delivery My favourite ...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>catch.com.au</td>\n",
       "      <td>2021-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501</td>\n",
       "      <td>By Terry</td>\n",
       "      <td>155.00</td>\n",
       "      <td>Makeup - Foundation - Mousse and Cream Foundation</td>\n",
       "      <td>So very expensive, but probably the best found...</td>\n",
       "      <td>5</td>\n",
       "      <td>Eclat Opulent</td>\n",
       "      <td>byterry.com</td>\n",
       "      <td>2021-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>914bf776-64b8-44b9-8b95-6cbbcf8944f5</td>\n",
       "      <td>Paul Sebastian</td>\n",
       "      <td>9.64</td>\n",
       "      <td>Men - Shaving - Post Shave</td>\n",
       "      <td>One of our favorite fragrances, at a great pri...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Fragrance!</td>\n",
       "      <td>zulily.com</td>\n",
       "      <td>2019-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>914bf776-64b8-44b9-8b95-6cbbcf8944f5</td>\n",
       "      <td>Paul Sebastian</td>\n",
       "      <td>9.64</td>\n",
       "      <td>Men - Shaving - Post Shave</td>\n",
       "      <td>This is one of my husband favorite cologne, so...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overstock.com</td>\n",
       "      <td>2019-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>914bf776-64b8-44b9-8b95-6cbbcf8944f5</td>\n",
       "      <td>Paul Sebastian</td>\n",
       "      <td>9.64</td>\n",
       "      <td>Men - Shaving - Post Shave</td>\n",
       "      <td>all of the above reasons. Its my husbands favo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome fragrance</td>\n",
       "      <td>ebay.com</td>\n",
       "      <td>2019-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>914bf776-64b8-44b9-8b95-6cbbcf8944f5</td>\n",
       "      <td>Paul Sebastian</td>\n",
       "      <td>9.64</td>\n",
       "      <td>Men - Shaving - Post Shave</td>\n",
       "      <td>great product and super fast shipping !!!!!!!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>great price, fast shipping !!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>fragrancex.com</td>\n",
       "      <td>2019-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>914bf776-64b8-44b9-8b95-6cbbcf8944f5</td>\n",
       "      <td>Paul Sebastian</td>\n",
       "      <td>9.64</td>\n",
       "      <td>Men - Shaving - Post Shave</td>\n",
       "      <td>My favorite cologne on my hubby. Women complim...</td>\n",
       "      <td>5</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>ebay.com</td>\n",
       "      <td>2019-02-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  product_id           brand  price_usd  \\\n",
       "0       b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501        By Terry     155.00   \n",
       "1       b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501        By Terry     155.00   \n",
       "2       b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501        By Terry     155.00   \n",
       "3       b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501        By Terry     155.00   \n",
       "4       b42e0e8e-63f9-41c1-a6c1-4f7c24b6a501        By Terry     155.00   \n",
       "...                                      ...             ...        ...   \n",
       "999995  914bf776-64b8-44b9-8b95-6cbbcf8944f5  Paul Sebastian       9.64   \n",
       "999996  914bf776-64b8-44b9-8b95-6cbbcf8944f5  Paul Sebastian       9.64   \n",
       "999997  914bf776-64b8-44b9-8b95-6cbbcf8944f5  Paul Sebastian       9.64   \n",
       "999998  914bf776-64b8-44b9-8b95-6cbbcf8944f5  Paul Sebastian       9.64   \n",
       "999999  914bf776-64b8-44b9-8b95-6cbbcf8944f5  Paul Sebastian       9.64   \n",
       "\n",
       "                                                 category  \\\n",
       "0       Makeup - Foundation - Mousse and Cream Foundation   \n",
       "1       Makeup - Foundation - Mousse and Cream Foundation   \n",
       "2       Makeup - Foundation - Mousse and Cream Foundation   \n",
       "3       Makeup - Foundation - Mousse and Cream Foundation   \n",
       "4       Makeup - Foundation - Mousse and Cream Foundation   \n",
       "...                                                   ...   \n",
       "999995                         Men - Shaving - Post Shave   \n",
       "999996                         Men - Shaving - Post Shave   \n",
       "999997                         Men - Shaving - Post Shave   \n",
       "999998                         Men - Shaving - Post Shave   \n",
       "999999                         Men - Shaving - Post Shave   \n",
       "\n",
       "                                              review_text  review_rating  \\\n",
       "0       I love this - just makes you look so healthy a...              5   \n",
       "1       Great coverage while allowing your skin to shi...              5   \n",
       "2       Absolutely wonderful product. I use this as a ...              5   \n",
       "3       Amazing price and quick delivery My favourite ...              5   \n",
       "4       So very expensive, but probably the best found...              5   \n",
       "...                                                   ...            ...   \n",
       "999995  One of our favorite fragrances, at a great pri...              5   \n",
       "999996  This is one of my husband favorite cologne, so...              5   \n",
       "999997  all of the above reasons. Its my husbands favo...              5   \n",
       "999998   great product and super fast shipping !!!!!!!!!               5   \n",
       "999999  My favorite cologne on my hubby. Women complim...              5   \n",
       "\n",
       "                                             review_title            shop  \\\n",
       "0                                                   Great     spacenk.com   \n",
       "1                                      Beautiful coverage    mecca.com.au   \n",
       "2                              Lovely glowy base product!     spacenk.com   \n",
       "3                                                     NaN    catch.com.au   \n",
       "4                                           Eclat Opulent     byterry.com   \n",
       "...                                                   ...             ...   \n",
       "999995                                   Great Fragrance!      zulily.com   \n",
       "999996                                                NaN   Overstock.com   \n",
       "999997                                  Awesome fragrance        ebay.com   \n",
       "999998  great price, fast shipping !!!!!!!!!!!!!!!!!!!...  fragrancex.com   \n",
       "999999                                           Love it!        ebay.com   \n",
       "\n",
       "       review_published  \n",
       "0            2021-01-21  \n",
       "1            2021-01-17  \n",
       "2            2021-01-14  \n",
       "3            2021-01-12  \n",
       "4            2021-01-08  \n",
       "...                 ...  \n",
       "999995       2019-02-13  \n",
       "999996       2019-02-10  \n",
       "999997       2019-02-06  \n",
       "999998       2019-02-06  \n",
       "999999       2019-02-06  \n",
       "\n",
       "[1000000 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('reviews.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e40806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 500000 rows for project to reduce computational power\n",
    "sample_df = df[0:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c387824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'brand', 'price_usd', 'category', 'review_text',\n",
       "       'review_rating', 'review_title', 'shop', 'review_published'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8f456",
   "metadata": {},
   "source": [
    "### Data Cleaning and preprocessing\n",
    "- Drop rows with empty review texts\n",
    "- Drop rows with duplicate lines\n",
    "- Remove punctuation and convert all text to lowercase\n",
    "- Removing numbers\n",
    "- Removing extra whitespace\n",
    "- Removing stop-words (extremely common words which do not provide any\n",
    "analytic information and tend to be of little value i.e. a, and, are etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3db87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id               0\n",
       "brand                    0\n",
       "price_usd                0\n",
       "category                 0\n",
       "review_text              0\n",
       "review_rating            0\n",
       "review_title        234119\n",
       "shop                     0\n",
       "review_published         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for empty rows or null values\n",
    "sample_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32086b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values?\n",
    "sample_df = sample_df.dropna()\n",
    "\n",
    "# drop duplicate rows for review text\n",
    "selected_df = sample_df.drop_duplicates(['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7546627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using package - preprocess_kgptalkie to preprocess data\n",
    "''' https://github.com/laxmimerit/preprocess_kgptalkie '''\n",
    "\n",
    "import preprocess_kgptalkie as ps\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "def remove_emoji(row):\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", row)\n",
    "    return new_text\n",
    "\n",
    "def preprocess_data(row):\n",
    "    row = str(row).lower().replace('\\\\', '').replace('_', ' ')\n",
    "    row = ps.cont_exp(row)\n",
    "    row = ps.remove_accented_chars(row)\n",
    "    row = ps.remove_special_chars(row)\n",
    "    row = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", row)\n",
    "    row = remove_emoji(row)\n",
    "    \n",
    "    return row\n",
    "\n",
    "# apply preprocess function to all rows in dataframe\n",
    "selected_df['review_text'] = selected_df['review_text'].apply(lambda row: preprocess_data(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6457285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242503, 20000), (242503,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# using tfidf to get x and y vectors and features\n",
    "tfidf = TfidfVectorizer(max_features=20000, sublinear_tf=True, norm='l2', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "X = tfidf.fit_transform(selected_df['review_text'])\n",
    "y = selected_df['review_rating']\n",
    "\n",
    "# fit to SVM linear svc model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "201f43a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For Naive Bayes:\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.71      0.52      3261\n",
      "           2       0.23      0.21      0.22      2334\n",
      "           3       0.27      0.35      0.30      3256\n",
      "           4       0.32      0.48      0.38      6952\n",
      "           5       0.90      0.71      0.80     32698\n",
      "\n",
      "    accuracy                           0.63     48501\n",
      "   macro avg       0.42      0.49      0.44     48501\n",
      "weighted avg       0.71      0.63      0.66     48501\n",
      "\n",
      "\n",
      " For svm:\n",
      "Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.54      0.49      3261\n",
      "           2       0.21      0.27      0.23      2334\n",
      "           3       0.24      0.29      0.26      3256\n",
      "           4       0.35      0.32      0.33      6952\n",
      "           5       0.86      0.83      0.85     32698\n",
      "\n",
      "    accuracy                           0.67     48501\n",
      "   macro avg       0.42      0.45      0.43     48501\n",
      "weighted avg       0.69      0.67      0.68     48501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamunopriye/Documents/Invisible/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# import classifiers \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "# train classifiers\n",
    "def train_classifier(clf, X_train, X_test, y_train, y_test):\n",
    "    # fit and train model \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf\n",
    "\n",
    "model_clf ={ MultinomialNB(alpha=1.0, fit_prior=False):'Naive Bayes', LinearSVC(C = 20, class_weight='balanced'):'svm'} \n",
    "\n",
    "\n",
    "#loop through each model to create different classifiers\n",
    "for clf in model_clf:\n",
    "    \n",
    "    # train classifiers\n",
    "    pred, clf = train_classifier(clf, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # store classifier for each model\n",
    "    if model_clf[clf] == 'svm':\n",
    "        svm_clf = clf\n",
    "    else:\n",
    "        nb_clf = clf\n",
    "   \n",
    "    # get and print report\n",
    "    report = classification_report(y_test, pred)\n",
    "    print(f\"\\n For {model_clf[clf]}:\")\n",
    "    #print(f\"Confusion matrix:\\n{confusion_matrix(y_test, pred)}\")\n",
    "    print(f\"Report: \\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905d189",
   "metadata": {},
   "source": [
    "### testing classifiers with random texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bba49fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing SVM\n",
    "text = 'This product is a bit fake '\n",
    "text =   preprocess_data(text)\n",
    "vec = tfidf.transform([text])\n",
    "svm_clf.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f0c8df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing NB\n",
    "text = 'This product is a bit fake'\n",
    "text = preprocess_data(text)\n",
    "vec = tfidf.transform([text])\n",
    "nb_clf.predict(vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
